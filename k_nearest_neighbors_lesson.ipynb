{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9163bb59",
   "metadata": {},
   "source": [
    "# KNN\n",
    "\n",
    "### What is KNN?\n",
    "\n",
    "- Supervised algorithm\n",
    "- Makes predictions based on how close a new data point is to known data points\n",
    "- Lazy (computation is performed when the model is implemented)\n",
    "- Sensitive to scaling\n",
    "\n",
    "Link: [KNN Diagram](https://cambridgecoding.files.wordpress.com/2016/01/knn2.jpg)\n",
    "\n",
    "#### Pros:\n",
    "\n",
    "1. Simple to implement \n",
    "2. Performs calculations \"just in time\"\n",
    "3. Data is easy to keep up to date to keep predictions accurate\n",
    "\n",
    "#### Cons:\n",
    "\n",
    "1. Need to determine how many neighbors is optimal\n",
    "2. Computation cost is high (has to calculate every single distance to every feature)\n",
    "3. Data must be stored and accessible to the model\n",
    "4. Complexity arises with higher dimensions (multiple features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8427cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# knn submodules from scikit learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# Data Acquisition\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c04b9",
   "metadata": {},
   "source": [
    "## Acquire data\n",
    "\n",
    "- Use the `iris` dataset from pydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbd9558-fa50-4243-9649-fe0d7df660f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "1             5.1          3.5           1.4          0.2      setosa\n",
       "2             4.9          3.0           1.4          0.2      setosa\n",
       "3             4.7          3.2           1.3          0.2      setosa\n",
       "4             4.6          3.1           1.5          0.2      setosa\n",
       "5             5.0          3.6           1.4          0.2      setosa\n",
       "6             5.4          3.9           1.7          0.4      setosa\n",
       "7             4.6          3.4           1.4          0.3      setosa\n",
       "8             5.0          3.4           1.5          0.2      setosa\n",
       "9             4.4          2.9           1.4          0.2      setosa\n",
       "10            4.9          3.1           1.5          0.1      setosa\n",
       "11            5.4          3.7           1.5          0.2      setosa\n",
       "12            4.8          3.4           1.6          0.2      setosa\n",
       "13            4.8          3.0           1.4          0.1      setosa\n",
       "14            4.3          3.0           1.1          0.1      setosa\n",
       "15            5.8          4.0           1.2          0.2      setosa\n",
       "16            5.7          4.4           1.5          0.4      setosa\n",
       "17            5.4          3.9           1.3          0.4      setosa\n",
       "18            5.1          3.5           1.4          0.3      setosa\n",
       "19            5.7          3.8           1.7          0.3      setosa\n",
       "20            5.1          3.8           1.5          0.3      setosa\n",
       "21            5.4          3.4           1.7          0.2      setosa\n",
       "22            5.1          3.7           1.5          0.4      setosa\n",
       "23            4.6          3.6           1.0          0.2      setosa\n",
       "24            5.1          3.3           1.7          0.5      setosa\n",
       "25            4.8          3.4           1.9          0.2      setosa\n",
       "26            5.0          3.0           1.6          0.2      setosa\n",
       "27            5.0          3.4           1.6          0.4      setosa\n",
       "28            5.2          3.5           1.5          0.2      setosa\n",
       "29            5.2          3.4           1.4          0.2      setosa\n",
       "30            4.7          3.2           1.6          0.2      setosa\n",
       "31            4.8          3.1           1.6          0.2      setosa\n",
       "32            5.4          3.4           1.5          0.4      setosa\n",
       "33            5.2          4.1           1.5          0.1      setosa\n",
       "34            5.5          4.2           1.4          0.2      setosa\n",
       "35            4.9          3.1           1.5          0.2      setosa\n",
       "36            5.0          3.2           1.2          0.2      setosa\n",
       "37            5.5          3.5           1.3          0.2      setosa\n",
       "38            4.9          3.6           1.4          0.1      setosa\n",
       "39            4.4          3.0           1.3          0.2      setosa\n",
       "40            5.1          3.4           1.5          0.2      setosa\n",
       "41            5.0          3.5           1.3          0.3      setosa\n",
       "42            4.5          2.3           1.3          0.3      setosa\n",
       "43            4.4          3.2           1.3          0.2      setosa\n",
       "44            5.0          3.5           1.6          0.6      setosa\n",
       "45            5.1          3.8           1.9          0.4      setosa\n",
       "46            4.8          3.0           1.4          0.3      setosa\n",
       "47            5.1          3.8           1.6          0.2      setosa\n",
       "48            4.6          3.2           1.4          0.2      setosa\n",
       "49            5.3          3.7           1.5          0.2      setosa\n",
       "50            5.0          3.3           1.4          0.2      setosa\n",
       "51            7.0          3.2           4.7          1.4  versicolor\n",
       "52            6.4          3.2           4.5          1.5  versicolor\n",
       "53            6.9          3.1           4.9          1.5  versicolor\n",
       "54            5.5          2.3           4.0          1.3  versicolor\n",
       "55            6.5          2.8           4.6          1.5  versicolor\n",
       "56            5.7          2.8           4.5          1.3  versicolor\n",
       "57            6.3          3.3           4.7          1.6  versicolor\n",
       "58            4.9          2.4           3.3          1.0  versicolor\n",
       "59            6.6          2.9           4.6          1.3  versicolor\n",
       "60            5.2          2.7           3.9          1.4  versicolor\n",
       "61            5.0          2.0           3.5          1.0  versicolor\n",
       "62            5.9          3.0           4.2          1.5  versicolor\n",
       "63            6.0          2.2           4.0          1.0  versicolor\n",
       "64            6.1          2.9           4.7          1.4  versicolor\n",
       "65            5.6          2.9           3.6          1.3  versicolor\n",
       "66            6.7          3.1           4.4          1.4  versicolor\n",
       "67            5.6          3.0           4.5          1.5  versicolor\n",
       "68            5.8          2.7           4.1          1.0  versicolor\n",
       "69            6.2          2.2           4.5          1.5  versicolor\n",
       "70            5.6          2.5           3.9          1.1  versicolor\n",
       "71            5.9          3.2           4.8          1.8  versicolor\n",
       "72            6.1          2.8           4.0          1.3  versicolor\n",
       "73            6.3          2.5           4.9          1.5  versicolor\n",
       "74            6.1          2.8           4.7          1.2  versicolor\n",
       "75            6.4          2.9           4.3          1.3  versicolor\n",
       "76            6.6          3.0           4.4          1.4  versicolor\n",
       "77            6.8          2.8           4.8          1.4  versicolor\n",
       "78            6.7          3.0           5.0          1.7  versicolor\n",
       "79            6.0          2.9           4.5          1.5  versicolor\n",
       "80            5.7          2.6           3.5          1.0  versicolor\n",
       "81            5.5          2.4           3.8          1.1  versicolor\n",
       "82            5.5          2.4           3.7          1.0  versicolor\n",
       "83            5.8          2.7           3.9          1.2  versicolor\n",
       "84            6.0          2.7           5.1          1.6  versicolor\n",
       "85            5.4          3.0           4.5          1.5  versicolor\n",
       "86            6.0          3.4           4.5          1.6  versicolor\n",
       "87            6.7          3.1           4.7          1.5  versicolor\n",
       "88            6.3          2.3           4.4          1.3  versicolor\n",
       "89            5.6          3.0           4.1          1.3  versicolor\n",
       "90            5.5          2.5           4.0          1.3  versicolor\n",
       "91            5.5          2.6           4.4          1.2  versicolor\n",
       "92            6.1          3.0           4.6          1.4  versicolor\n",
       "93            5.8          2.6           4.0          1.2  versicolor\n",
       "94            5.0          2.3           3.3          1.0  versicolor\n",
       "95            5.6          2.7           4.2          1.3  versicolor\n",
       "96            5.7          3.0           4.2          1.2  versicolor\n",
       "97            5.7          2.9           4.2          1.3  versicolor\n",
       "98            6.2          2.9           4.3          1.3  versicolor\n",
       "99            5.1          2.5           3.0          1.1  versicolor\n",
       "100           5.7          2.8           4.1          1.3  versicolor\n",
       "101           6.3          3.3           6.0          2.5   virginica\n",
       "102           5.8          2.7           5.1          1.9   virginica\n",
       "103           7.1          3.0           5.9          2.1   virginica\n",
       "104           6.3          2.9           5.6          1.8   virginica\n",
       "105           6.5          3.0           5.8          2.2   virginica\n",
       "106           7.6          3.0           6.6          2.1   virginica\n",
       "107           4.9          2.5           4.5          1.7   virginica\n",
       "108           7.3          2.9           6.3          1.8   virginica\n",
       "109           6.7          2.5           5.8          1.8   virginica\n",
       "110           7.2          3.6           6.1          2.5   virginica\n",
       "111           6.5          3.2           5.1          2.0   virginica\n",
       "112           6.4          2.7           5.3          1.9   virginica\n",
       "113           6.8          3.0           5.5          2.1   virginica\n",
       "114           5.7          2.5           5.0          2.0   virginica\n",
       "115           5.8          2.8           5.1          2.4   virginica\n",
       "116           6.4          3.2           5.3          2.3   virginica\n",
       "117           6.5          3.0           5.5          1.8   virginica\n",
       "118           7.7          3.8           6.7          2.2   virginica\n",
       "119           7.7          2.6           6.9          2.3   virginica\n",
       "120           6.0          2.2           5.0          1.5   virginica\n",
       "121           6.9          3.2           5.7          2.3   virginica\n",
       "122           5.6          2.8           4.9          2.0   virginica\n",
       "123           7.7          2.8           6.7          2.0   virginica\n",
       "124           6.3          2.7           4.9          1.8   virginica\n",
       "125           6.7          3.3           5.7          2.1   virginica\n",
       "126           7.2          3.2           6.0          1.8   virginica\n",
       "127           6.2          2.8           4.8          1.8   virginica\n",
       "128           6.1          3.0           4.9          1.8   virginica\n",
       "129           6.4          2.8           5.6          2.1   virginica\n",
       "130           7.2          3.0           5.8          1.6   virginica\n",
       "131           7.4          2.8           6.1          1.9   virginica\n",
       "132           7.9          3.8           6.4          2.0   virginica\n",
       "133           6.4          2.8           5.6          2.2   virginica\n",
       "134           6.3          2.8           5.1          1.5   virginica\n",
       "135           6.1          2.6           5.6          1.4   virginica\n",
       "136           7.7          3.0           6.1          2.3   virginica\n",
       "137           6.3          3.4           5.6          2.4   virginica\n",
       "138           6.4          3.1           5.5          1.8   virginica\n",
       "139           6.0          3.0           4.8          1.8   virginica\n",
       "140           6.9          3.1           5.4          2.1   virginica\n",
       "141           6.7          3.1           5.6          2.4   virginica\n",
       "142           6.9          3.1           5.1          2.3   virginica\n",
       "143           5.8          2.7           5.1          1.9   virginica\n",
       "144           6.8          3.2           5.9          2.3   virginica\n",
       "145           6.7          3.3           5.7          2.5   virginica\n",
       "146           6.7          3.0           5.2          2.3   virginica\n",
       "147           6.3          2.5           5.0          1.9   virginica\n",
       "148           6.5          3.0           5.2          2.0   virginica\n",
       "149           6.2          3.4           5.4          2.3   virginica\n",
       "150           5.9          3.0           5.1          1.8   virginica"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data('iris')\n",
    "\n",
    "## Change column names\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62257b",
   "metadata": {},
   "source": [
    "#### Note: Inspect the units of the features\n",
    "\n",
    "Scaling is important for an algorithm like knn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ceb089",
   "metadata": {},
   "source": [
    "## Prepare/Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cfa8a6",
   "metadata": {},
   "source": [
    "[Train Test Split Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431d0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8be468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07e4bcac",
   "metadata": {},
   "source": [
    "### 1. Split into train, validate, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36851e68-f47c-442d-8db9-302800a6d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, \n",
    "                               stratify=df['species'], \n",
    "                               train_size=0.8, \n",
    "                               random_state=1729)\n",
    "\n",
    "train, validate = train_test_split(train, \n",
    "                                   stratify=train['species'], \n",
    "                                   train_size=0.7, \n",
    "                                   random_state=1729)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff7158c",
   "metadata": {},
   "source": [
    "### 2. Spliting based on features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2212f",
   "metadata": {},
   "source": [
    "Create X and Y columns where: \n",
    "\n",
    "   - X is the feature\n",
    "   \n",
    "   - Y is the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7bbf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns = ['species', 'petal_length', 'petal_width'])\n",
    "y_train = train.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2bf9171-13b2-49dd-89d6-d41a5dcc5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = validate.drop(columns = ['species', 'petal_length', 'petal_width'])\n",
    "y_validate = validate.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9654ba-019a-4d1b-b7bb-2dc040d7c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns = ['species', 'petal_length', 'petal_width'])\n",
    "y_test = test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b205c01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sepal_length', ylabel='sepal_width'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data = train, x='sepal_length', y='sepal_width', hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2cc75c",
   "metadata": {},
   "source": [
    "## k-nearest neighbors model\n",
    "\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165a2cb",
   "metadata": {},
   "source": [
    "\n",
    "#### Create KNN Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5105e76-6442-4622-b3ea-cb127b795601",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf08ef82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec61bcf1",
   "metadata": {},
   "source": [
    "#### Fit the Model to the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d5354fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dfbcc8",
   "metadata": {},
   "source": [
    "#### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d76be200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76fc4c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      virginica\n",
       "1     versicolor\n",
       "2         setosa\n",
       "3     versicolor\n",
       "4         setosa\n",
       "5      virginica\n",
       "6      virginica\n",
       "7     versicolor\n",
       "8     versicolor\n",
       "9         setosa\n",
       "10    versicolor\n",
       "11        setosa\n",
       "12     virginica\n",
       "13     virginica\n",
       "14    versicolor\n",
       "15        setosa\n",
       "16     virginica\n",
       "17        setosa\n",
       "18     virginica\n",
       "19     virginica\n",
       "20    versicolor\n",
       "21     virginica\n",
       "22        setosa\n",
       "23     virginica\n",
       "24     virginica\n",
       "25        setosa\n",
       "26        setosa\n",
       "27        setosa\n",
       "28    versicolor\n",
       "29        setosa\n",
       "30    versicolor\n",
       "31        setosa\n",
       "32        setosa\n",
       "33    versicolor\n",
       "34        setosa\n",
       "35     virginica\n",
       "36        setosa\n",
       "37     virginica\n",
       "38     virginica\n",
       "39     virginica\n",
       "40     virginica\n",
       "41     virginica\n",
       "42    versicolor\n",
       "43    versicolor\n",
       "44        setosa\n",
       "45    versicolor\n",
       "46     virginica\n",
       "47        setosa\n",
       "48    versicolor\n",
       "49        setosa\n",
       "50        setosa\n",
       "51     virginica\n",
       "52        setosa\n",
       "53     virginica\n",
       "54    versicolor\n",
       "55        setosa\n",
       "56    versicolor\n",
       "57     virginica\n",
       "58        setosa\n",
       "59    versicolor\n",
       "60    versicolor\n",
       "61    versicolor\n",
       "62    versicolor\n",
       "63     virginica\n",
       "64    versicolor\n",
       "65    versicolor\n",
       "66    versicolor\n",
       "67    versicolor\n",
       "68     virginica\n",
       "69    versicolor\n",
       "70     virginica\n",
       "71        setosa\n",
       "72    versicolor\n",
       "73    versicolor\n",
       "74        setosa\n",
       "75     virginica\n",
       "76        setosa\n",
       "77        setosa\n",
       "78    versicolor\n",
       "79    versicolor\n",
       "80        setosa\n",
       "81    versicolor\n",
       "82        setosa\n",
       "83     virginica\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4c70e5",
   "metadata": {},
   "source": [
    "#### Estimate Probability of the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7d1fee1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict_proba() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict_proba() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6206c764-c490-42b7-9d49-cf06e14971c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53665fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913df819",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e3bdf1",
   "metadata": {},
   "source": [
    "#### Compute the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1b7c632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_accuracy = knn.score(X_train, y_train)\n",
    "knn_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "423c981b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0,  0],\n",
       "       [ 0, 27,  1],\n",
       "       [ 0,  3, 25]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9f9b5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       setosa  versicolor  virginica\n",
       "species                                  \n",
       "setosa          28           0          0\n",
       "versicolor       0          27          1\n",
       "virginica        0           3         25"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed74dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "In [40]:\n",
    "rubric = pd.DataFrame(\n",
    "    {'pred_0': ['True Positive', 'False Negative', 'False Negative'],\n",
    "     'pred_1': ['False Positive', 'True Positive']\n",
    "    }, index=['actual_0','actual_1']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb894ba-b142-4983-9665-213632ce0d55",
   "metadata": {},
   "source": [
    "#### Create a Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23abda2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.953846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.952320</td>\n",
       "      <td>0.952320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>28.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           setosa  versicolor  virginica  accuracy  macro avg  weighted avg\n",
       "precision     1.0    0.900000   0.961538  0.952381   0.953846      0.953846\n",
       "recall        1.0    0.964286   0.892857  0.952381   0.952381      0.952381\n",
       "f1-score      1.0    0.931034   0.925926  0.952381   0.952320      0.952320\n",
       "support      28.0   28.000000  28.000000  0.952381  84.000000     84.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06634c05",
   "metadata": {},
   "source": [
    "## Changing the k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a122e64-f880-4e6f-bd01-bda9af2d11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of neighbors, as well as a weight (certain datasets will affect the \n",
    "# determination)\n",
    "knn5 = KNeighborsClassifier(n_neighbors = 5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8bb1c461-34db-47cc-ab30-e692ff592ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b47aa370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "y_pred5 = knn5.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afca6d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       0.82      0.64      0.72        28\n",
      "   virginica       0.71      0.86      0.77        28\n",
      "\n",
      "    accuracy                           0.83        84\n",
      "   macro avg       0.84      0.83      0.83        84\n",
      "weighted avg       0.84      0.83      0.83        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50ee3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       0.90      0.96      0.93        28\n",
      "   virginica       0.96      0.89      0.93        28\n",
      "\n",
      "    accuracy                           0.95        84\n",
      "   macro avg       0.95      0.95      0.95        84\n",
      "weighted avg       0.95      0.95      0.95        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8175a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44dc48b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc403b0",
   "metadata": {},
   "source": [
    "## Finding the best value for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1b44609-2901-424e-9b01-bacebafb20db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.75      0.75      0.75        12\n",
      "   virginica       0.75      0.75      0.75        12\n",
      "\n",
      "    accuracy                           0.83        36\n",
      "   macro avg       0.83      0.83      0.83        36\n",
      "weighted avg       0.83      0.83      0.83        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# for knn\n",
    "print(classification_report(y_validate, knn.predict(X_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1dab0d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       0.92      1.00      0.96        12\n",
      "  versicolor       0.78      0.58      0.67        12\n",
      "   virginica       0.64      0.75      0.69        12\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.78      0.78      0.77        36\n",
      "weighted avg       0.78      0.78      0.77        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# for knn5\n",
    "print(classification_report(y_validate, knn5.predict(X_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab625ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "model_accuracies = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    nknn = KNeighborsClassifier(n_neighbors = i)\n",
    "    nknn.fit(X_train, y_train)\n",
    "    model_accuracies[f'{i} - Neighbors'] = {\n",
    "        'Train Score:': round(nknn.score(X_train, y_train), 2),\n",
    "        'Validate Score:': round(nknn.score(X_validate, y_validate), 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0bfbfe51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KNeighborsClassifier(n_neighbors=1),\n",
       " KNeighborsClassifier(n_neighbors=2),\n",
       " KNeighborsClassifier(n_neighbors=3),\n",
       " KNeighborsClassifier(n_neighbors=4),\n",
       " KNeighborsClassifier(),\n",
       " KNeighborsClassifier(n_neighbors=6),\n",
       " KNeighborsClassifier(n_neighbors=7),\n",
       " KNeighborsClassifier(n_neighbors=8),\n",
       " KNeighborsClassifier(n_neighbors=9)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2469b5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Score:</th>\n",
       "      <th>Validate Score:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 - Neighbors</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 - Neighbors</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 - Neighbors</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 - Neighbors</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 - Neighbors</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 - Neighbors</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 - Neighbors</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 - Neighbors</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 - Neighbors</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Train Score:  Validate Score:\n",
       "1 - Neighbors          0.95             0.83\n",
       "2 - Neighbors          0.86             0.72\n",
       "3 - Neighbors          0.88             0.75\n",
       "4 - Neighbors          0.83             0.67\n",
       "5 - Neighbors          0.83             0.78\n",
       "6 - Neighbors          0.81             0.86\n",
       "7 - Neighbors          0.83             0.83\n",
       "8 - Neighbors          0.82             0.75\n",
       "9 - Neighbors          0.81             0.81"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_accuracies).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c0ec7",
   "metadata": {},
   "source": [
    "## Moving forward\n",
    "\n",
    "- We selected `sepal_length` and `sepal_width` as features. \n",
    "     - Build new models with different and/or additional features. \n",
    "\n",
    "\n",
    "- Tuning hyperparameters\n",
    "\n",
    "    `'weights'`: Uniform weight is the default (all points are treated equally). \n",
    "    Switch to a distance-weighted approach where nearer neighbors are given more weight in the voting process\n",
    "    \n",
    "    `'algorithm'`: Large datasets use a sampling algorithm to save on computational cost. We can try different samplers. \n",
    "    \n",
    "    `'metric'`: There is more than one way to measure distance\n",
    "\n",
    "\n",
    "- There are very similar models that we can try e.g. `RadiusNeighborsClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f218e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
